# **Набор кейсов для DevOps-инженера с подсказками и логикой решения**
 
```python

1. Что такое CI/CD?
2. Напишите простой демон для systemd, который будет поддерживать работу процесса и перезапускаться в случае выхода из строя процесса.
3. Что такое inode в Linux?
4. Сделайте реализацию blue/green стратегии деплоймента для Kubernetes на основе деплойментов, сервиса и ingress’а. Опишите как переключать версии.
5. Напишите политику для AWS S3 бакета, которая разрешает доступ только с определенных IP адресов.
6. Объясните паттерны IaaS/PaaS/SaaS на примере пиццы.
7. Есть условное Node.js приложение и неправильно написанный Dockerfile, который не будет кэшироваться и будет занимать много места.
Нужно переписать его в соответствии с best-practice
#плохой файл
FROM ubuntu:18.04
COPY ./src /app
RUN apt-get update -y
RUN apt-get install -y nodejs
RUN npm install
ENTRYPOINT [“npm”]
CMD [“run”, “prod”]

8. С помощью чего можно ограничить в Kubernetes сетевое взаимодействие между подами? Приведите пример. Надо ли отдельно включать данный механизм?
Что такое POSIX?
9. Приведите основные типы DNS записей и для чего они используются?

```
## 1. Что такое CI/CD?

### CI/CD (Непрерывная Интеграция / Непрерывная Доставка/Развертывание) своими словами

Представьте, что вы пишете очень сложный и важный код вместе с большой командой (как в случае с Terraform). CI/CD — это набор автоматизированных практик, которые помогают вам выпускать этот код быстро, часто и с минимальным количеством ошибок.

Это можно разбить на две части:

### 1. CI (Continuous Integration) — Непрерывная Интеграция
Суть: Это процесс частого слияния кода и автоматической проверки.

Как это работает: Каждый разработчик вносит небольшие изменения в код несколько раз в день. Вместо того чтобы ждать неделю, чтобы все объединили свои работы (и потом 3 дня искали конфликты), изменения сразу же автоматически собираются и проверяются на специальном сервере.

Зачем нужно: Чтобы “интегрировать” код в общую базу часто и убедиться, что новая маленькая правка никого другого не сломала. Если что-то сломалось (например, тесты не проходят), система немедленно сообщает об этом команде, и поломку легко исправить, пока она свежая.

Сравнение: Это как если бы во время строительства дома рабочие не собирали все детали в конце месяца, а сразу после изготовления каждой балки проверяли, подходит ли она к уже установленной конструкции.

### 2. CD (Continuous Delivery / Continuous Deployment) — Непрерывная Доставка / Развертывание
Суть: Это процесс автоматической подготовки кода к выпуску (Delivery) или автоматического выпуска (Deployment).

Continuous Delivery (Доставка): После того как код прошел все проверки CI, он автоматически упаковывается и доставляется в место, где его можно легко развернуть (например, в тестовый или “staging” сервер). Решение о том, когда нажать кнопку “Выпустить в продакшн”, принимает человек.
Continuous Deployment (Развертывание): Это следующий шаг. Если все тесты прошли успешно, код автоматически разворачивается в рабочую среду (продакшн) без участия человека.
Зачем нужно: Чтобы доставлять пользователям ценность (новые функции, исправления багов) как можно быстрее и надежнее. Чем меньше ручных шагов при релизе, тем меньше человеческих ошибок.

### Итог:
CI/CD — это конвейер (пайплайн), который берет ваш исходный код, автоматически собирает его, прогоняет через тесты (CI), а затем, если все в порядке, упаковывает и доставляет (CD) готовый продукт до конечного пользователя или до ручного тестировщика.

Это позволяет командам выпускать изменения быстрее, чаще и безопаснее.

### CI/CD — это не одна конкретная программа, а скорее набор практик и инструментов, которые работают вместе. Есть множество программных продуктов, которые реализуют эти практики.

Вот основные категории инструментов, которые используются для CI/CD:

### 1. Системы управления версиями (Version Control Systems - VCS)

Назначение: Хранение кода, отслеживание изменений, совместная работа. Это фундамент CI/CD.

Примеры:
Git (самый популярный)
Subversion (SVN)
Mercurial

### 2. Серверы CI/CD (CI/CD Servers / Orchestrators)

Назначение: Это “мозг” всего процесса. Они следят за изменениями в VCS, запускают нужные этапы пайплайна (сборка, тестирование, развертывание) и координируют работу других инструментов.

Примеры:
Jenkins: Один из старейших и самых мощных, очень гибкий, с огромным количеством плагинов.
GitLab CI/CD: Встроен в платформу GitLab, очень удобен для тех, кто уже использует GitLab для хостинга кода.
GitHub Actions: Встроен в GitHub, позволяет создавать рабочие процессы прямо в репозитории.
CircleCI: Облачный сервис, простой в настройке.
Travis CI: Еще один популярный облачный сервис, часто используется для open-source проектов.
Azure DevOps Pipelines: Решение от Microsoft.
Bitbucket Pipelines: Для пользователей Bitbucket.

### 3. Инструменты сборки (Build Tools)

Назначение: Компиляция кода, упаковка артефактов (например, исполняемых файлов, Docker-образов).

Примеры:
Для Java: Maven, Gradle
Для JavaScript/Node.js: npm, Yarn, Webpack
Для C/C++: Make, CMake
Для Go: go build (встроен в язык)
Для .NET: MSBuild, .NET CLI
Docker: Для сборки контейнеров.

### 4. Инструменты тестирования (Testing Frameworks)

Назначение: Автоматическая проверка кода на наличие ошибок.

Примеры:
Unit-тесты: JUnit (Java), pytest (Python), Mocha/Jest (JavaScript), Go testing package
Интеграционные тесты: Часто используют те же фреймворки, но тестируют взаимодействие компонентов.
E2E (End-to-End) тесты: Selenium, Cypress, Playwright
Статический анализ кода: SonarQube, ESLint, Pylint

### 5. Инструменты управления артефактами (Artifact Management)

Назначение: Хранение собранных артефактов (готовых к развертыванию версий вашего приложения), чтобы их можно было легко найти и использовать на следующих этапах.

Примеры:
Nexus Repository Manager
Artifactory
Docker Registry (для Docker-образов)

### 6. Инструменты развертывания (Deployment Tools)

Назначение: Автоматическое развертывание приложения на серверах или в облачных средах.

Примеры:
Docker Compose, Kubernetes: Для оркестрации контейнеров.
Ansible, Chef, Puppet, SaltStack: Инструменты управления конфигурацией, которые могут выполнять развертывание.
Terraform, Pulumi: Для Infrastructure as Code (IaC) – автоматическое создание и управление инфраструктурой.
AWS CodeDeploy, Azure Pipelines Release, Google Cloud Deploy: Облачные сервисы для развертывания.
Helm: Для управления развертыванием приложений в Kubernetes.

Как они работают вместе:

Сервер CI/CD (например, Jenkins или GitLab CI) оркестрирует весь процесс. Когда разработчик пушит изменения в Git, сервер CI/CD:

Получает уведомление.
Скачивает код.
Использует инструмент сборки для компиляции кода и создания артефакта.
Запускает инструменты тестирования для проверки артефакта.
Если тесты прошли, отправляет артефакт в менеджер артефактов.
Затем использует инструменты развертывания, чтобы доставить артефакт на серверы или в облако.
Так что, CI/CD — это экосистема, состоящая из множества разных программ, каждая из которых выполняет свою часть работы.

## 2. Напишите простой демон для systemd, который будет поддерживать работу процесса и перезапускаться в случае выхода из строя процесса.

### 1. Создание юнит-файла systemd
Мы создадим файл .service, который будет описывать, как systemd должен управлять нашим демоном.

**Создайте файл демона (ваш основной скрипт/приложение): Предположим, у вас есть скрипт на Python, который вы хотите запустить как демон. Назовем его ` my_daemon.py `**

```python
python

#!/usr/bin/env python3

import time
import sys
import os

def main():
    # Получаем PID процесса
    pid = os.getpid()
    print(f"Daemon started with PID: {pid}")

    # Имитируем работу (например, запись в лог или выполнение задачи)
    counter = 0
    while True:
        print(f"Daemon process {pid} is running. Counter: {counter}")
        counter += 1
        time.sleep(5) # Пауза в 5 секунд

        # Пример условия для "сбоя" (можно раскомментировать для тестирования перезапуска)
        # if counter > 5:
        #     print(f"Daemon process {pid} simulating crash!")
        #     sys.exit(1) # Имитация сбоя

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("Daemon received interrupt, exiting gracefully.")
        sys.exit(0)
    except Exception as e:
        print(f"Daemon encountered an unhandled exception: {e}")
        sys.exit(1)

```
### Важные моменты для этого скрипта:

* Он должен быть исполняемым (chmod +x my_daemon.py).
* Он должен корректно обрабатывать сигналы (хотя systemd может и сам их посылать).
* Он должен возвращать ненулевой код выхода при сбое, чтобы systemd понял, что произошла ошибка.

### 2. Создайте юнит-файл systemd: Создайте файл с расширением .service в каталоге
###   **/etc/systemd/system/. Назовем его, например, ` my-daemon.service `**

```python
systemd

[Unit]
Description=My Custom Daemon
After=network.target

[Service]
ExecStart=/usr/bin/python3 /opt/my_daemon/my_daemon.py
Restart=on-failure
RestartSec=5
User=mydaemonuser
Group=mydaemonuser
WorkingDirectory=/opt/my_daemon

[Install]
WantedBy=multi-user.target

```

Разбор секций:

### [Unit]:

Description: Краткое описание вашего сервиса.
After=network.target: Указывает, что ваш сервис должен запускаться после того, как сеть будет готова. Это часто важно для сетевых сервисов.

### [Service]:

ExecStart: Самая важная строка. Указывает полный путь к исполняемому файлу (вашему скрипту или программе) и его аргументы. Убедитесь, что путь к интерпретатору (например, /usr/bin/python3) и к вашему скрипту указаны верно.
Restart=on-failure: Ключевая настройка для перезапуска. Systemd будет автоматически перезапускать сервис, если он завершится с ненулевым кодом выхода (то есть, произошел сбой).
RestartSec=5: Указывает, что перед перезапуском systemd подождет 5 секунд. Это предотвращает слишком частые перезапуски, если сервис падает сразу после старта.
User=mydaemonuser и Group=mydaemonuser: Рекомендуется запускать сервисы от непривилегированного пользователя для повышения безопасности. Вам нужно будет создать этого пользователя (например, sudo useradd -r -s /bin/false mydaemonuser).
WorkingDirectory: Указывает рабочий каталог для процесса.

### [Install]:

WantedBy=multi-user.target: Эта строка указывает, что сервис должен запускаться при достижении уровня запуска multi-user.target (обычный режим работы системы без графического интерфейса, когда система готова к приему пользователей).

### 3. **Создайте пользователя и группу (если вы их указали в User и Group):**

```python
sudo useradd -r -s /bin/false mydaemonuser
sudo groupadd mydaemonuser
sudo usermod -a -G mydaemonuser mydaemonuser

```

(если mydaemonuser еще не существует)

### 4. **Создайте каталог для скрипта и поместите туда скрипт: В нашем примере, это /opt/my_daemon/my_daemon.py**

```python
sudo mkdir -p /opt/my_daemon
sudo cp my_daemon.py /opt/my_daemon/
sudo chown mydaemonuser:mydaemonuser /opt/my_daemon/my_daemon.py
sudo chmod +x /opt/my_daemon/my_daemon.py

```

### 5. Перезагрузите systemd: После создания нового юнит-файла systemd нужно уведомить о его существовании.

```
sudo systemctl daemon-reload

```

### 6. Включите автозапуск сервиса при загрузке системы:

```

sudo systemctl enable my-daemon.service

```

### 7. Запустите сервис:

```

sudo systemctl start my-daemon.service

```

### 8. Проверьте статус сервиса:

```
sudo systemctl status my-daemon.service

```
Вы должны увидеть, что сервис работает. Если он упал, вы увидите информацию о последнем сбое и о том, что systemd пытается его перезапустить.

### 9. Посмотрите логи:

```
sudo journalctl -u my-daemon.service -f

```

Эта команда будет показывать логи вашего демона в реальном времени.

### Как это работает при сбое:

Если ваш скрипт ` my_daemon.py`  завершится с ошибкой (вернет ненулевой код выхода, например, `sys.exit(1))`, systemd заметит это благодаря `Restart=on-failure`. После паузы, заданной `RestartSec=5`, systemd попытается запустить сервис снова, выполнив `ExecStart`. Так будет продолжаться до тех пор, пока сервис не завершится успешно (`код выхода 0`) или пока вы вручную не остановите сервис.

## Что такое inode в Linux?

### Inode в Linux (своими словами)

Представьте, что у вас есть большая библиотека с книгами. Чтобы найти нужную книгу, вам нужен не только каталог, но и точное место, где она находится (номер полки, стеллажа).

В Linux inode — это как “карточка” или “запись” о файле или каталоге в файловой системе. Эта карточка содержит всю необходимую информацию о файле, кроме его имени и самого содержимого.

Что хранится в inode:

Тип файла: Это обычный файл, каталог, символическая ссылка, блочное устройство, символьное устройство, именованный канал (FIFO) или сокет?
Права доступа: Кто может читать, записывать или выполнять файл (владелец, группа, все остальные)?
Владелец и группа: ID пользователя и группы, которым принадлежит файл.
Размер файла: Сколько байт занимает файл.
Метки времени: Когда файл был последний раз изменен (mtime), когда к нему был последний раз получен доступ (atime), когда был изменен его inode (ctime).
Счетчик ссылок: Сколько имен (hard links) указывают на этот inode. Когда счетчик становится равным нулю, файл может быть удален.
Указатели на блоки данных: Это самая важная часть. Inode хранит адреса (или указатели) на реальные блоки на жестком диске, где находится само содержимое файла. Inode не хранит данные напрямую, он знает, где их найти.
Как это работает вместе с именем файла:

Имя файла (например, my_document.txt) хранится в каталоге. Каталог — это просто специальный тип файла, который содержит список пар “имя файла” -> “номер inode”.
Когда вы запрашиваете файл по имени (например, cat my_document.txt), система сначала ищет my_document.txt в текущем каталоге.
Найдя запись в каталоге, система получает номер inode.
Затем, используя номер inode, система находит соответствующую “карточку” inode, которая содержит всю информацию о файле, включая указатели на блоки данных.
Используя эти указатели, система читает содержимое файла с диска.
Зачем нужен такой механизм?

Эффективность: Имена файлов хранятся в каталогах, а вся остальная метаинформация — в inode. Это позволяет быстро находить файлы по имени и потом быстро получать к ним доступ.
Hard Links: Несколько имен файлов могут указывать на один и тот же inode. Это позволяет иметь “жесткие ссылки” на один и тот же файл. Когда вы удаляете одно имя, счетчик ссылок в inode уменьшается, но сам файл (и его данные) удаляется только тогда, когда счетчик становится равным нулю.
Независимость имени от данных: Если вы переименуете файл, меняется только запись в каталоге. Сам inode и его указатели на данные остаются прежними. Если же вы удалите файл, система просто “освободит” inode, но данные останутся на диске до тех пор, пока не будут перезаписаны другими файлами.
Кратко: Inode — это “идентификатор” и “описатель” файла в файловой системе Linux, который знает всё о файле, кроме его имени и содержимого. Он является ключевым звеном между именем файла и его данными на диске.


## 5. Напишите политику для AWS S3 бакета, которая разрешает доступ только с определенных IP адресов.

### Пример политики для AWS S3 бакета, которая разрешает доступ только с определенных IP-адресов.

**Важно: Вместо <YOUR-BUCKET-NAME> и <YOUR-IP-ADDRESS> подставьте реальные значения.**
```json
json
{
    "Version": "2012-10-17",
    "Id": "S3PolicyId",
    "Statement": [
        {
            "Sid": "Allow access only from specific IPs",
            "Effect": "Allow",
            "Principal": "*",
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::<YOUR-BUCKET-NAME>",
                "arn:aws:s3:::<YOUR-BUCKET-NAME>/*"
            ],
            "Condition": {
                "IpAddress": {
                    "aws:SourceIp": [
                        "<YOUR-FIRST-IP-ADDRESS>/32",
                        "<YOUR-SECOND-IP-ADDRESS>/32",
                        "<YOUR-THIRD-IP-ADDRESS>/32"
                        // Добавьте сюда другие IP-адреса или CIDR-блоки, если необходимо
                    ]
                }
            }
        }
    ]
}

```


























